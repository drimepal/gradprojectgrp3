{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender name data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import pickle\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal gender names\n",
    "df_1 = pd.read_csv('gender_name.csv') \n",
    "df_2 = pd.read_csv('gender_name_2.csv')\n",
    "df = df_1[['name','sex']]\n",
    "df_universal_gender_names = pd.concat([df, df_2[['name','sex']]], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norwegian gender names\n",
    "df = pd.read_excel('norwegian_female_names.xlsx')\n",
    "df['origin'] = \"norwegian\"\n",
    "df_norwegian_female_names = df[['name', 'origin']]\n",
    "df_norwegian_female_names['sex'] = \"F\"\n",
    "\n",
    "df = pd.read_excel('norwegian_male_names.xlsx')\n",
    "df = df.groupby('name')\n",
    "df = pd.DataFrame(df, columns = ['name', 'sex'])\n",
    "df['origin'] = \"norwegian\"\n",
    "df_norwegian_male_names = df[['name', 'origin']]\n",
    "df_norwegian_female_names['sex'] = \"M\"\n",
    "\n",
    "df_norway = pd.concat([df_norwegian_female_names, df_norwegian_male_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding swedish names:\n",
    "list_of_swed_male_names = ['Hugo', 'Matteo', 'Walter', 'Harry', 'Vincent', 'Charlie', 'Arvid', 'Frans', 'Sam', 'Louie', 'Otto', 'Malte', 'Elton', 'Ebbe', 'Love', 'Olle', 'Melvin', 'Albin', 'Jack', 'Frank', 'Tage', 'Colin', 'Noel', 'Sixten', 'Viggo', 'Vidar', 'Melker', 'Loke', 'Ivar', 'Milo', 'Sigge', 'Alvin', 'Kian', 'Nicholas', 'Anton', 'Milton', 'Vilgot', 'Wilmer', 'Wilhelm', 'Elis', 'Dante', 'Ture', 'Elvin', 'Folke', 'Algot', 'Hjalmar', 'Vide', 'Alvar', 'Ted', 'Alve', 'Joel', 'Björn', 'Otis', 'Svante']\n",
    "list_of_swed_female_names = ['Alice', 'Elsa', 'Wilma', 'Freja', 'Vera', 'Ines', 'Ester', 'Ellen', 'Molly', 'Lo', 'Nova', 'Mila', 'Lova', 'Juni', 'Isabelle', 'Edith', 'Nellie', 'Leia', 'Meja', 'Livia', 'Rut', 'Tyra', 'Cleo', 'Majken', 'Lovisa', 'Sally', 'Elin', 'Lykke', 'Hailey', 'Bonnie', 'Hilma', 'Melina', 'Mira', 'Märta', 'Hilda', 'Melissa', 'Svea', 'Zoe', 'Ilse', 'Stina', 'Joline', 'Lovis', 'Tilde', 'Elsie', 'Siri', 'Elina', 'Maryam', 'Belle', 'Felicia', 'Matilda', 'Bianca', 'Moa', 'Ayla', 'Idun', 'Millie']\n",
    "\n",
    "df_swed_m = pd.DataFrame(list_of_swed_male_names, columns = ['name'])\n",
    "df_swed_m['origin'] = \"swedish\"\n",
    "df_swed_m['sex'] = \"M\"\n",
    "df_swed_f = pd.DataFrame(list_of_swed_female_names, columns = ['name'])\n",
    "df_swed_f['origin'] = \"swedish\"\n",
    "df_swed_f['sex'] = \"F\"\n",
    "\n",
    "df_sweden = pd.concat([df_swed_f, df_swed_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Islamic gender names\n",
    "islamic_female_name = []\n",
    "with open('islamske_kvinne_navn.txt','r') as file:   \n",
    "    # reading each line    \n",
    "    for line in file:   \n",
    "        # reading each word        \n",
    "        for name in line.split():   \n",
    "            # displaying the words\n",
    "            name = name.strip(\",\")           \n",
    "            islamic_female_name.append(name)\n",
    "df_islamic_female_name = pd.DataFrame(islamic_female_name, columns=[\"name\"])\n",
    "df_islamic_female_name['origin'] = \"arabic\"\n",
    "df_islamic_female_name['sex'] = \"F\"\n",
    "\n",
    "islamic_male_name = []\n",
    "with open('islamske_mannenavn_navn.txt','r') as file:   \n",
    "    # reading each line    \n",
    "    for line in file:   \n",
    "        # reading each word        \n",
    "        for name in line.split():   \n",
    "            # displaying the words\n",
    "            name = name.strip(\",\")           \n",
    "            islamic_male_name.append(name)\n",
    "df_islamic_male_name = pd.DataFrame(islamic_male_name, columns=[\"name\"])\n",
    "df_islamic_male_name['origin'] = \"arabic\"\n",
    "df_islamic_male_name['sex'] = \"M\"\n",
    "\n",
    "df_arabic = pd.concat([df_islamic_male_name, df_islamic_female_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Islamic gender names\n",
    "universal_name_origin = []\n",
    "first_line = True\n",
    "with open('name_origin.csv','r') as file:   \n",
    "    for line in file:\n",
    "        if first_line != True:\n",
    "\n",
    "            row = []\n",
    "            for item in line.split(\",\"):   \n",
    "                item = item.strip(\" \")\n",
    "                item = item.strip(\"\\n\")\n",
    "                row.append(item)\n",
    "            universal_name_origin.append(row)\n",
    "        else:\n",
    "            first_line = False\n",
    "df_universal_name = pd.DataFrame(universal_name_origin, columns=[\"index\", \"name\", \"origin\"])\n",
    "df_universal_name = df_universal_name[[\"name\", \"origin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining into a df_gender_name\n",
    "df = pd.concat([df_universal_name,\n",
    "                df_norway,\n",
    "                df_sweden,\n",
    "                df_arabic\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yiddish', 'gaelic', 'african', 'irish', 'hungarian', 'german',\n",
       "       'swedish', 'japanese', 'italian', 'american', 'hawaiian', 'greek',\n",
       "       'polynesian', 'scandinavian', 'spanish', 'celtic', 'old-english',\n",
       "       'korean', 'sanskrit', 'african-american', 'hebrew', 'norse',\n",
       "       'chinese', 'finnish', 'persian', 'scottish', 'slavic', 'english',\n",
       "       'old-norse', 'dutch', 'armenian', 'welsh', 'polish', 'teutonic',\n",
       "       'russian', 'egyptian', 'arabic', 'swahili', 'native-american',\n",
       "       'old-french', 'french', 'middle-english', 'latin', 'vietnamese',\n",
       "       'danish', 'hindi', 'old-german', 'turkish', 'indian',\n",
       "       'czechoslovakian', 'norwegian'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"origin\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scandinavian = ['scandinavian' ,'norwegian', 'swedish', 'danish', 'norse', 'old-norse']\n",
    "sami_finish = ['finnish']\n",
    "african = ['swahili', 'african']\n",
    "arabic = ['turkish', 'arabic', 'persian', 'egyptian']\n",
    "western_european = ['teutonic','dutch', 'scottish','english','spanish','american','old-english','italian', 'irish','old-french', 'french', 'middle-english', 'latin', 'old-german', 'german']\n",
    "celtic = ['gaelic', 'celtic', 'welsh']\n",
    "eastern_european = ['polish', 'czechoslovakian', 'slavic', 'russian', 'armenian']\n",
    "asian = ['hindi', 'indian', 'vietnamese', 'japanese', 'korean', 'chinese', 'sanskrit']\n",
    "other_european = ['hungarian', 'greek']\n",
    "pacific_islander = ['hawaiian', 'polynesian']\n",
    "non_european_american = ['african-american','native-american']\n",
    "jewish = ['yiddish', 'hebrew']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_classefier(origin):\n",
    "    if origin in scandinavian:\n",
    "        return 'scandinavian'\n",
    "    elif origin in sami_finish:\n",
    "        return 'sami_finish'\n",
    "    elif origin in african:\n",
    "        return 'african'\n",
    "    elif origin in arabic:\n",
    "        return 'arabic'\n",
    "    elif origin in western_european:\n",
    "        return 'western_european'\n",
    "    elif origin in celtic:\n",
    "        return 'celtic'\n",
    "    elif origin in eastern_european:\n",
    "        return 'eastern_european'\n",
    "    elif origin in asian:\n",
    "        return 'asian'\n",
    "    elif origin in other_european:\n",
    "        return 'other_european'\n",
    "    elif origin in pacific_islander:\n",
    "        return 'pacific_islander'\n",
    "    elif origin in non_european_american:\n",
    "        return 'non_european_american'\n",
    "    elif origin in jewish:\n",
    "        return 'jewish'\n",
    "    else:\n",
    "        print(\"NOT FOUND\")\n",
    "        print(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nordic = ['finnish','scandinavian' ,'norwegian', 'swedish', 'danish', 'norse', 'old-norse']\n",
    "african_middel_eastern = ['swahili', 'african','turkish', 'arabic', 'persian', 'egyptian']\n",
    "western_european = ['hungarian', 'greek','gaelic', 'celtic', 'welsh','teutonic','dutch', 'scottish','english','spanish','american','old-english','italian', 'irish','old-french', 'french', 'middle-english', 'latin', 'old-german', 'german']\n",
    "eastern_european = ['polish', 'czechoslovakian', 'slavic', 'russian', 'armenian']\n",
    "asian = ['hindi', 'indian', 'vietnamese', 'japanese', 'korean', 'chinese', 'sanskrit']\n",
    "other = ['yiddish', 'hebrew', 'african-american','native-american', 'hawaiian', 'polynesian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_region_classefier(origin):\n",
    "    if origin in nordic:\n",
    "        return 'nordic'\n",
    "    elif origin in african_middel_eastern:\n",
    "        return 'african_middel_eastern'\n",
    "    elif origin in western_european:\n",
    "        return 'western_european'\n",
    "    elif origin in eastern_european:\n",
    "        return 'eastern_european'\n",
    "    elif origin in asian:\n",
    "        return 'asian'\n",
    "    elif origin in other:\n",
    "        return 'other'\n",
    "    else:\n",
    "        print(\"NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'] = df['origin'].map(region_classefier)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['super_region'] = df['origin'].map(super_region_classefier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>origin</th>\n",
       "      <th>region</th>\n",
       "      <th>super_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gershon</td>\n",
       "      <td>yiddish</td>\n",
       "      <td>jewish</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lantz</td>\n",
       "      <td>yiddish</td>\n",
       "      <td>jewish</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zaide</td>\n",
       "      <td>yiddish</td>\n",
       "      <td>jewish</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zalman</td>\n",
       "      <td>yiddish</td>\n",
       "      <td>jewish</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zindel</td>\n",
       "      <td>yiddish</td>\n",
       "      <td>jewish</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Zubaidah</td>\n",
       "      <td>arabic</td>\n",
       "      <td>arabic</td>\n",
       "      <td>african_middel_eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>Zuhal</td>\n",
       "      <td>arabic</td>\n",
       "      <td>arabic</td>\n",
       "      <td>african_middel_eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Zuhur</td>\n",
       "      <td>arabic</td>\n",
       "      <td>arabic</td>\n",
       "      <td>african_middel_eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>Zulaikha</td>\n",
       "      <td>arabic</td>\n",
       "      <td>arabic</td>\n",
       "      <td>african_middel_eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Zulfa</td>\n",
       "      <td>arabic</td>\n",
       "      <td>arabic</td>\n",
       "      <td>african_middel_eastern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5569 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   origin  region            super_region\n",
       "0     Gershon  yiddish  jewish                   other\n",
       "1       Lantz  yiddish  jewish                   other\n",
       "2       Zaide  yiddish  jewish                   other\n",
       "3      Zalman  yiddish  jewish                   other\n",
       "4      Zindel  yiddish  jewish                   other\n",
       "..        ...      ...     ...                     ...\n",
       "825  Zubaidah   arabic  arabic  african_middel_eastern\n",
       "826     Zuhal   arabic  arabic  african_middel_eastern\n",
       "827     Zuhur   arabic  arabic  african_middel_eastern\n",
       "828  Zulaikha   arabic  arabic  african_middel_eastern\n",
       "829     Zulfa   arabic  arabic  african_middel_eastern\n",
       "\n",
       "[5569 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data to two lists:\n",
    "# And last minute clean up, removal of \" \" characters.\n",
    "name_list = df.name.tolist()\n",
    "temp_name_list = []\n",
    "X = []\n",
    "for name in name_list:\n",
    "    X.append(name.strip())\n",
    "y1 = df.origin.tolist()\n",
    "y2 = df.region.tolist()\n",
    "y3 = df.super_region.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_name(X):\n",
    "    for idx, name in enumerate(X):\n",
    "        for char in name:\n",
    "            if char == \" \" or char == \"½\" or char == \"Ã\":\n",
    "                return(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5569\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing more to remove\n"
     ]
    }
   ],
   "source": [
    "#index = remove_unwanted_name(X)\n",
    "while True:\n",
    "    try:\n",
    "        index = remove_unwanted_name(X)\n",
    "        X.pop(index)\n",
    "        y1.pop(index)\n",
    "        y2.pop(index)\n",
    "        y3.pop(index)\n",
    "    except:\n",
    "        print(\"Nothing more to remove\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5528\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X:\n",
    "    for char in name:\n",
    "        if char.lower() not in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','æ','ø','å','à','á','ä','ö','ü','í','é',\"'\",'-',]:\n",
    "            print(char)\n",
    "            print(name)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [X,y1,y2,y3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data\n",
    "parent = path.abspath(path.join(\"gender_name_data_managment.ipynb\", \"../..\"))\n",
    "path = \"/processed/\"\n",
    "file_name = \"origin_data\"\n",
    "\n",
    "with open(f'{parent + path + file_name}.obj', 'wb') as f:\n",
    "\tpickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c2940c5258610f9a2b978227281dc0bf3c3e3ce460e55d30a45b10f147711e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
